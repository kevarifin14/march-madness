{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pytorch as torch\n",
    "\n",
    "POWER_CONF = ['SEC', 'B10', 'B12', 'P12', 'ACC']\n",
    "NUM_FEATURES = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_season_res_df = pd.read_csv('data/RegularSeasonCompactResults.csv', index_col=[\"Season\", \"Daynum\", \"Wteam\", \"Lteam\"]).loc[2002:]\n",
    "tournament_res_df = pd.read_csv('data/TourneyCompactResults.csv', index_col=[\"Season\", \"Daynum\", \"Wteam\", \"Lteam\"]).loc[2002:]\n",
    "id_to_team = pd.read_csv('data/Teams.csv', index_col='Team_Id').to_dict()['Team_Name']\n",
    "team_to_id = dict((v,k) for k,v in id_to_team.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.concat([reg_season_res_df, tournament_res_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_df(year):\n",
    "    df = pd.read_csv('data/{}.csv'.format(year))\n",
    "    df['year'] = [year] * df.shape[0]\n",
    "    return df\n",
    "\n",
    "def replace(team):\n",
    "    df.replace(to_replace=team, value=team.replace('.', ''), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Cal St', 'CS'), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Eastern ', 'E '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Western ', 'W '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Northern ', 'N '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Southern ', 'S '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Saint ', 'St '), inplace=True)\n",
    "    \n",
    "df = pd.concat([load_df(year) for year in range(2002, 2018)])\n",
    "df.drop(['13', '14', '15', '16', '17', '18', '19', '20'], 1, inplace=True)\n",
    "_ = [replace(team) for team in set(df['Team_9'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.replace(to_replace=\"St Mary's\", value=\"St Mary's CA\", inplace=True)\n",
    "df.replace(to_replace=\"Mount St Mary's\", value=\"Mt St Mary's\", inplace=True)\n",
    "df.replace(to_replace=\"Grambling St\", value=\"Grambling\", inplace=True)\n",
    "df.replace(to_replace=\"VCU\", value=\"VA Commonwealth\", inplace=True)\n",
    "df.replace(to_replace='Northwestern St', value='Northwestern LA', inplace=True)\n",
    "df.replace(to_replace='Middle Tennessee', value='MTSU', inplace=True)\n",
    "df.replace(to_replace='Cal Poly', value='Cal Poly SLO', inplace=True)\n",
    "df.replace(to_replace='Texas Southern', value='TX Southern', inplace=True)\n",
    "df.replace(to_replace='Mississippi Valley St', value='MS Valley St', inplace=True)\n",
    "df.replace(to_replace='UMass Lowell', value='MA Lowell', inplace=True)\n",
    "df.replace(to_replace='Loyola Chicago', value='Loyola-Chicago', inplace=True)\n",
    "df.replace(to_replace='Coastal Carolina', value='Coastal Car', inplace=True)\n",
    "df.replace(to_replace='American', value='American Univ', inplace=True)\n",
    "df.replace(to_replace='Bethune Cookman', value='Bethune-Cookman', inplace=True)\n",
    "df.replace(to_replace='LIU Brooklyn', value='Brooklyn', inplace=True)\n",
    "df.replace(to_replace='The Citadel', value='Citadel', inplace=True)\n",
    "df.replace(to_replace='Cal St Fullerton', value='CS Fullerton', inplace=True)\n",
    "df.replace(to_replace='Cal St Bakersfield', value='CS Bakersfield', inplace=True)\n",
    "df.replace(to_replace='Cal St Northridge', value='CS Northridge', inplace=True)\n",
    "df.replace(to_replace='W Kentucky', value='WKU', inplace=True)\n",
    "df.replace(to_replace='Arkansas Pine Bluff', value='Ark Pine Bluff', inplace=True)\n",
    "df.replace(to_replace='Southern', value='Southern Univ', inplace=True)\n",
    "df.replace(to_replace='Southeast Missouri St', value='SE Missouri St', inplace=True)\n",
    "df.replace(to_replace='Sacramento St', value='CS Sacramento', inplace=True)\n",
    "df.replace(to_replace='Green Bay', value='WI Green Bay', inplace=True)\n",
    "df.replace(to_replace='Boston University', value='Boston Univ', inplace=True)\n",
    "df.replace(to_replace='North Carolina St', value='NC State', inplace=True)\n",
    "df.replace(to_replace='South Carolina St', value='South Carolina', inplace=True)\n",
    "df.replace(to_replace='North Carolina Central', value='NC Central', inplace=True)\n",
    "df.replace(to_replace='S Utah', value='Southern Utah', inplace=True)\n",
    "df.replace(to_replace='Houston Baptist', value='Houston Bap', inplace=True)\n",
    "df.replace(to_replace='North Dakota St', value='N Dakota St', inplace=True)\n",
    "df.replace(to_replace='Monmouth', value='Monmouth NJ', inplace=True)\n",
    "df.replace(to_replace='East Tennessee St', value='ETSU', inplace=True)\n",
    "df.replace(to_replace='Florida Gulf Coast', value='FL Gulf Coast', inplace=True)\n",
    "df.replace(to_replace='Florida Atlantic', value='FL Atlantic', inplace=True)\n",
    "df.replace(to_replace='Little Rock', value='Ark Little Rock', inplace=True)\n",
    "df.replace(to_replace='North Carolina A&T', value='NC A&T', inplace=True)\n",
    "df.replace(to_replace='N Iowa', value='Northern Iowa', inplace=True)\n",
    "df.replace(to_replace='Kennesaw St', value='Kennesaw', inplace=True)\n",
    "df.replace(to_replace='South Dakota St', value='S Dakota St', inplace=True)\n",
    "df.replace(to_replace='Albany', value='Albany NY', inplace=True)\n",
    "df.replace(to_replace='FIU', value='Florida Intl', inplace=True)\n",
    "df.replace(to_replace='Central Michigan', value='C Michigan', inplace=True)\n",
    "df.replace(to_replace='Prairie View A&M', value='Prairie View', inplace=True)\n",
    "df.replace(to_replace='N Arizona', value='Northern Arizona', inplace=True)\n",
    "df.replace(to_replace='Illinois Chicago', value='IL Chicago', inplace=True)\n",
    "df.replace(to_replace='Stephen F Austin', value='SF Austin', inplace=True)\n",
    "df.replace(to_replace='SIU Edwardsville', value='Edwardsville', inplace=True)\n",
    "df.replace(to_replace='Tennessee Martin', value='TN Martin', inplace=True)\n",
    "df.replace(to_replace='Georgia Southern', value='Ga Southern', inplace=True)\n",
    "df.replace(to_replace='Charleston Southern', value='Charleston So', inplace=True)\n",
    "df.replace(to_replace='Central Arkansas', value='Cent Arkansas', inplace=True)\n",
    "df.replace(to_replace='Milwaukee', value='WI Milwaukee', inplace=True)\n",
    "df.replace(to_replace='Central Connecticut', value='Central Conn', inplace=True)\n",
    "df.replace(to_replace='Abilene Christian', value='Abilene Chr', inplace=True)\n",
    "df.replace(to_replace='USC Upstate', value='SC Upstate', inplace=True)\n",
    "df.replace(to_replace=\"St Joseph's\", value=\"St Joseph's PA\", inplace=True)\n",
    "df.replace(to_replace='George Washington', value='G Washington', inplace=True)\n",
    "df.replace(to_replace='UC Santa Barbara', value='Santa Barbara', inplace=True)\n",
    "df.replace(to_replace='College of Charleston', value='Col Charleston', inplace=True)\n",
    "df.replace(to_replace='Maryland E Shore', value='MD E Shore', inplace=True)\n",
    "df.replace(to_replace='Fairleigh Dickinson', value='F Dickinson', inplace=True)\n",
    "df.replace(to_replace='Kent St', value='Kent', inplace=True)\n",
    "df.replace(to_replace='Southeastern Louisiana', value='SE Louisiana', inplace=True)\n",
    "df.replace(to_replace='Loyola Marymount', value='Loy Marymount', inplace=True)\n",
    "df.replace(to_replace='UT Rio Grande Valley', value='UTRGV', inplace=True)\n",
    "df.replace(to_replace='Nebraska Omaha', value='NE Omaha', inplace=True)\n",
    "df.replace(to_replace='Louisiana Monroe', value='ULM', inplace=True)\n",
    "df.replace(to_replace='Texas A&M Corpus Chris', value='TAM C. Christi', inplace=True)\n",
    "df.replace(to_replace='S Miss', value='Southern Miss', inplace=True)\n",
    "df.replace(to_replace='UTSA', value='UT San Antonio', inplace=True)\n",
    "df.replace(to_replace='UMKC', value='Missouri KC', inplace=True)\n",
    "df.replace(to_replace='Louisiana Lafayette', value='ULL', inplace=True)\n",
    "df.replace(to_replace='Fort Wayne', value='IPFW', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = [df.replace(to_replace=t, value=team_to_id[t], inplace=True) for t in set(df['Team_9'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_win_percent(record):\n",
    "    record = re.split('[-]', record)\n",
    "    return float(record[0]) / (float(record[0]) + float(record[1]))\n",
    "    \n",
    "df['W-L_9'] = df['W-L_9'].apply(extract_win_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def set_power_conf(conf):\n",
    "    return 1 if conf in POWER_CONF else 0\n",
    "\n",
    "df['Conf_9'] = df['Conf_9'].apply(set_power_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.set_index(['year', 'Team_9'], inplace=True)\n",
    "df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1000\n",
      "Iteration 2000\n",
      "Iteration 3000\n",
      "Iteration 4000\n",
      "Iteration 5000\n",
      "Iteration 6000\n",
      "Iteration 7000\n",
      "Iteration 8000\n",
      "Iteration 9000\n",
      "Iteration 10000\n",
      "Iteration 11000\n",
      "Iteration 12000\n",
      "Iteration 13000\n",
      "Iteration 14000\n",
      "Iteration 15000\n",
      "Iteration 16000\n",
      "Iteration 17000\n",
      "Iteration 19000\n",
      "Iteration 20000\n",
      "Iteration 21000\n",
      "Iteration 22000\n",
      "Iteration 23000\n",
      "Iteration 24000\n",
      "Iteration 25000\n",
      "Iteration 26000\n",
      "Iteration 27000\n",
      "Iteration 28000\n",
      "Iteration 29000\n",
      "Iteration 30000\n",
      "Iteration 31000\n",
      "Iteration 32000\n",
      "Iteration 33000\n",
      "Iteration 34000\n",
      "Iteration 35000\n",
      "Iteration 36000\n",
      "Iteration 37000\n",
      "Iteration 38000\n",
      "Iteration 39000\n",
      "Iteration 40000\n",
      "Iteration 41000\n",
      "Iteration 42000\n",
      "Iteration 43000\n",
      "Iteration 45000\n",
      "Iteration 46000\n",
      "Iteration 47000\n",
      "Iteration 48000\n",
      "Iteration 49000\n",
      "Iteration 50000\n",
      "Iteration 51000\n",
      "Iteration 52000\n",
      "Iteration 53000\n",
      "Iteration 54000\n",
      "Iteration 55000\n",
      "Iteration 56000\n",
      "Iteration 57000\n",
      "Iteration 58000\n",
      "Iteration 59000\n",
      "Iteration 60000\n",
      "Iteration 61000\n",
      "Iteration 62000\n",
      "Iteration 63000\n",
      "Iteration 64000\n",
      "Iteration 65000\n",
      "Iteration 66000\n",
      "Iteration 67000\n",
      "Iteration 68000\n",
      "Iteration 69000\n",
      "Iteration 70000\n",
      "Iteration 71000\n",
      "Iteration 72000\n",
      "Iteration 73000\n",
      "Iteration 74000\n",
      "Iteration 75000\n",
      "Iteration 76000\n",
      "Iteration 77000\n",
      "Iteration 78000\n",
      "Iteration 79000\n",
      "Iteration 80000\n",
      "Iteration 81000\n",
      "Iteration 82000\n"
     ]
    }
   ],
   "source": [
    "X, y = np.zeros(NUM_FEATURES), np.zeros(1)\n",
    "\n",
    "for i, (index, game) in enumerate(results_df.iterrows()):\n",
    "    year, _, w_team, l_team = index\n",
    "    ranked_teams = df.loc[year].index\n",
    "    if w_team not in ranked_teams or l_team not in ranked_teams: continue\n",
    "    w_stats = df.loc[year, w_team]\n",
    "    l_stats = df.loc[year, l_team]\n",
    "    \n",
    "    # 0 if right team wins, 1 if left team wins\n",
    "    if i % 2 == 0: X_i, y_i= l_stats - w_stats, 0\n",
    "    else: X_i, y_i = w_stats - l_stats, 1\n",
    "        \n",
    "    X = np.vstack((X, X_i))\n",
    "    y = np.vstack((X, y_i))\n",
    "    if i % 10000 == 0: print('Iteration {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.61552\n",
      "Test Accuracy: 0.6436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "model = LogisticRegression()\n",
    "X_shuf, y_shuf = shuffle(X_train[:50000], y_train[:50000, 0])\n",
    "model.fit(X_shuf, y_shuf)\n",
    "print(\"Train Accuracy: {0}\".format(model.score(X_shuf, y_shuf)))\n",
    "print(\"Test Accuracy: {0}\".format(model.score(X_train[-10000:], y_train[-10000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-514-b6e15cc7860e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
