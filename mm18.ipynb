{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "POWER_CONF = ['SEC', 'B10', 'B12', 'P12', 'ACC']\n",
    "NUM_FEATURES = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pull regular season and tournament results from 2002. For each game, we use data from kenpom.com which quantifies efficiency data and schedule data for each team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_season_res_df = pd.read_csv('data/RegularSeasonCompactResults.csv', index_col=[\"Season\", \"Daynum\", \"Wteam\", \"Lteam\"]).loc[2002:]\n",
    "tournament_res_df = pd.read_csv('data/TourneyCompactResults.csv', index_col=[\"Season\", \"Daynum\", \"Wteam\", \"Lteam\"]).loc[2002:]\n",
    "id_to_team = pd.read_csv('data/Teams.csv', index_col='Team_Id').to_dict()['Team_Name']\n",
    "team_to_id = dict((v,k) for k,v in id_to_team.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.concat([reg_season_res_df, tournament_res_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_df(year):\n",
    "    df = pd.read_csv('data/{}.csv'.format(year))\n",
    "    df['year'] = [year] * df.shape[0]\n",
    "    return df\n",
    "\n",
    "def replace(team):\n",
    "    df.replace(to_replace=team, value=team.replace('.', ''), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Cal St', 'CS'), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Eastern ', 'E '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Western ', 'W '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Northern ', 'N '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Southern ', 'S '), inplace=True)\n",
    "    df.replace(to_replace=team, value=team.replace('Saint ', 'St '), inplace=True)\n",
    "    \n",
    "df = pd.concat([load_df(year) for year in range(2002, 2018)])\n",
    "df.drop(['13', '14', '15', '16', '17', '18', '19', '20'], 1, inplace=True)\n",
    "_ = [replace(team) for team in set(df['Team_9'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.replace(to_replace=\"St Mary's\", value=\"St Mary's CA\", inplace=True)\n",
    "df.replace(to_replace=\"Mount St Mary's\", value=\"Mt St Mary's\", inplace=True)\n",
    "df.replace(to_replace=\"Grambling St\", value=\"Grambling\", inplace=True)\n",
    "df.replace(to_replace=\"VCU\", value=\"VA Commonwealth\", inplace=True)\n",
    "df.replace(to_replace='Northwestern St', value='Northwestern LA', inplace=True)\n",
    "df.replace(to_replace='Middle Tennessee', value='MTSU', inplace=True)\n",
    "df.replace(to_replace='Cal Poly', value='Cal Poly SLO', inplace=True)\n",
    "df.replace(to_replace='Texas Southern', value='TX Southern', inplace=True)\n",
    "df.replace(to_replace='Mississippi Valley St', value='MS Valley St', inplace=True)\n",
    "df.replace(to_replace='UMass Lowell', value='MA Lowell', inplace=True)\n",
    "df.replace(to_replace='Loyola Chicago', value='Loyola-Chicago', inplace=True)\n",
    "df.replace(to_replace='Coastal Carolina', value='Coastal Car', inplace=True)\n",
    "df.replace(to_replace='American', value='American Univ', inplace=True)\n",
    "df.replace(to_replace='Bethune Cookman', value='Bethune-Cookman', inplace=True)\n",
    "df.replace(to_replace='LIU Brooklyn', value='Brooklyn', inplace=True)\n",
    "df.replace(to_replace='The Citadel', value='Citadel', inplace=True)\n",
    "df.replace(to_replace='Cal St Fullerton', value='CS Fullerton', inplace=True)\n",
    "df.replace(to_replace='Cal St Bakersfield', value='CS Bakersfield', inplace=True)\n",
    "df.replace(to_replace='Cal St Northridge', value='CS Northridge', inplace=True)\n",
    "df.replace(to_replace='W Kentucky', value='WKU', inplace=True)\n",
    "df.replace(to_replace='Arkansas Pine Bluff', value='Ark Pine Bluff', inplace=True)\n",
    "df.replace(to_replace='Southern', value='Southern Univ', inplace=True)\n",
    "df.replace(to_replace='Southeast Missouri St', value='SE Missouri St', inplace=True)\n",
    "df.replace(to_replace='Sacramento St', value='CS Sacramento', inplace=True)\n",
    "df.replace(to_replace='Green Bay', value='WI Green Bay', inplace=True)\n",
    "df.replace(to_replace='Boston University', value='Boston Univ', inplace=True)\n",
    "df.replace(to_replace='North Carolina St', value='NC State', inplace=True)\n",
    "df.replace(to_replace='South Carolina St', value='South Carolina', inplace=True)\n",
    "df.replace(to_replace='North Carolina Central', value='NC Central', inplace=True)\n",
    "df.replace(to_replace='S Utah', value='Southern Utah', inplace=True)\n",
    "df.replace(to_replace='Houston Baptist', value='Houston Bap', inplace=True)\n",
    "df.replace(to_replace='North Dakota St', value='N Dakota St', inplace=True)\n",
    "df.replace(to_replace='Monmouth', value='Monmouth NJ', inplace=True)\n",
    "df.replace(to_replace='East Tennessee St', value='ETSU', inplace=True)\n",
    "df.replace(to_replace='Florida Gulf Coast', value='FL Gulf Coast', inplace=True)\n",
    "df.replace(to_replace='Florida Atlantic', value='FL Atlantic', inplace=True)\n",
    "df.replace(to_replace='Little Rock', value='Ark Little Rock', inplace=True)\n",
    "df.replace(to_replace='North Carolina A&T', value='NC A&T', inplace=True)\n",
    "df.replace(to_replace='N Iowa', value='Northern Iowa', inplace=True)\n",
    "df.replace(to_replace='Kennesaw St', value='Kennesaw', inplace=True)\n",
    "df.replace(to_replace='South Dakota St', value='S Dakota St', inplace=True)\n",
    "df.replace(to_replace='Albany', value='Albany NY', inplace=True)\n",
    "df.replace(to_replace='FIU', value='Florida Intl', inplace=True)\n",
    "df.replace(to_replace='Central Michigan', value='C Michigan', inplace=True)\n",
    "df.replace(to_replace='Prairie View A&M', value='Prairie View', inplace=True)\n",
    "df.replace(to_replace='N Arizona', value='Northern Arizona', inplace=True)\n",
    "df.replace(to_replace='Illinois Chicago', value='IL Chicago', inplace=True)\n",
    "df.replace(to_replace='Stephen F Austin', value='SF Austin', inplace=True)\n",
    "df.replace(to_replace='SIU Edwardsville', value='Edwardsville', inplace=True)\n",
    "df.replace(to_replace='Tennessee Martin', value='TN Martin', inplace=True)\n",
    "df.replace(to_replace='Georgia Southern', value='Ga Southern', inplace=True)\n",
    "df.replace(to_replace='Charleston Southern', value='Charleston So', inplace=True)\n",
    "df.replace(to_replace='Central Arkansas', value='Cent Arkansas', inplace=True)\n",
    "df.replace(to_replace='Milwaukee', value='WI Milwaukee', inplace=True)\n",
    "df.replace(to_replace='Central Connecticut', value='Central Conn', inplace=True)\n",
    "df.replace(to_replace='Abilene Christian', value='Abilene Chr', inplace=True)\n",
    "df.replace(to_replace='USC Upstate', value='SC Upstate', inplace=True)\n",
    "df.replace(to_replace=\"St Joseph's\", value=\"St Joseph's PA\", inplace=True)\n",
    "df.replace(to_replace='George Washington', value='G Washington', inplace=True)\n",
    "df.replace(to_replace='UC Santa Barbara', value='Santa Barbara', inplace=True)\n",
    "df.replace(to_replace='College of Charleston', value='Col Charleston', inplace=True)\n",
    "df.replace(to_replace='Maryland E Shore', value='MD E Shore', inplace=True)\n",
    "df.replace(to_replace='Fairleigh Dickinson', value='F Dickinson', inplace=True)\n",
    "df.replace(to_replace='Kent St', value='Kent', inplace=True)\n",
    "df.replace(to_replace='Southeastern Louisiana', value='SE Louisiana', inplace=True)\n",
    "df.replace(to_replace='Loyola Marymount', value='Loy Marymount', inplace=True)\n",
    "df.replace(to_replace='UT Rio Grande Valley', value='UTRGV', inplace=True)\n",
    "df.replace(to_replace='Nebraska Omaha', value='NE Omaha', inplace=True)\n",
    "df.replace(to_replace='Louisiana Monroe', value='ULM', inplace=True)\n",
    "df.replace(to_replace='Texas A&M Corpus Chris', value='TAM C. Christi', inplace=True)\n",
    "df.replace(to_replace='S Miss', value='Southern Miss', inplace=True)\n",
    "df.replace(to_replace='UTSA', value='UT San Antonio', inplace=True)\n",
    "df.replace(to_replace='UMKC', value='Missouri KC', inplace=True)\n",
    "df.replace(to_replace='Louisiana Lafayette', value='ULL', inplace=True)\n",
    "df.replace(to_replace='Fort Wayne', value='IPFW', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = [df.replace(to_replace=t, value=team_to_id[t], inplace=True) for t in set(df['Team_9'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_win_percent(record):\n",
    "    record = re.split('[-]', record)\n",
    "    return float(record[0]) / (float(record[0]) + float(record[1]))\n",
    "    \n",
    "df['W-L_9'] = df['W-L_9'].apply(extract_win_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_power_conf(conf):\n",
    "    return 1 if conf in POWER_CONF else 0\n",
    "\n",
    "df['Conf_9'] = df['Conf_9'].apply(set_power_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.set_index(['year', 'Team_9'], inplace=True)\n",
    "df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rankings_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_features_and_labels(results_df, rankings_df):\n",
    "    X, y = np.zeros(NUM_FEATURES), np.zeros(1)\n",
    "    \n",
    "    for i, (index, game) in enumerate(results_df.iterrows()):\n",
    "        year, _, w_team, l_team = index\n",
    "        ranked_teams = df.loc[year].index\n",
    "        if w_team not in ranked_teams or l_team not in ranked_teams: continue\n",
    "        w_stats = df.loc[year, w_team]\n",
    "        l_stats = df.loc[year, l_team]\n",
    "\n",
    "        if i % 2 == 0: X_i, y_i = l_stats - w_stats, 0\n",
    "        else: X_i, y_i = w_stats - l_stats, 1\n",
    "\n",
    "        X = np.vstack((X, X_i))\n",
    "        y = np.vstack((y, y_i))\n",
    "        if i % 10000 == 0: print('Iteration {}'.format(i))\n",
    "    return X[1:], y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 10000\n",
      "Iteration 20000\n",
      "Iteration 30000\n",
      "Iteration 40000\n",
      "Iteration 50000\n",
      "Iteration 60000\n",
      "Iteration 70000\n",
      "Iteration 80000\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_features_and_labels(results_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 10000\n",
      "Iteration 20000\n",
      "Iteration 30000\n",
      "Iteration 40000\n",
      "Iteration 50000\n",
      "Iteration 60000\n",
      "Iteration 70000\n",
      "Iteration 80000\n",
      "Iteration 0\n"
     ]
    }
   ],
   "source": [
    "reg_X, reg_y = generate_features_and_labels(reg_season_res_df, df)\n",
    "tourn_X, tourn_y = generate_features_and_labels(tournament_res_df, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the data through a simple logistic regression model to see if we get any signal from the data. Below is the results of training on a large portion of all games and testing on the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.61716\n",
      "Test Accuracy: 0.616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "X_shuf, y_shuf = shuffle(X[:50000], y[:50000, 0])\n",
    "model.fit(X_shuf, y_shuf)\n",
    "print(\"Train Accuracy: {0}\".format(model1.score(X_shuf[:50000], y_shuf[:50000])))\n",
    "print(\"Test Accuracy: {0}\".format(model1.score(X_shuf[-30000:], y_shuf[-30000:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do another experiment where we use regular season data to predict tournament results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6221575587301985\n",
      "Test Accuracy: 0.6589817483189241\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "X_shuf, y_shuf = shuffle(reg_X, reg_y[:, 0])\n",
    "model2.fit(X_shuf, y_shuf)\n",
    "print(\"Train Accuracy: {0}\".format(model2.score(X_shuf, y_shuf)))\n",
    "print(\"Test Accuracy: {0}\".format(model2.score(tourn_X, tourn_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-af9cfb1d6295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = X, y\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:\n",
    "            print('{0}, {1} loss: {2}'.format(epoch + 1, i + 1, running_loss / 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
